{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3b6224bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/BharathBandaru/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/BharathBandaru/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/BharathBandaru/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import numpy\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from tabulate import tabulate\n",
    "import re\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import numpy as np\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "from nltk.tokenize import word_tokenize as w_t \n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "stemmer = PorterStemmer()\n",
    "from autocorrect import Speller\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "import gensim\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim.parsing.preprocessing import STOPWORDS\n",
    "from nltk.stem import WordNetLemmatizer, SnowballStemmer\n",
    "nltk.download('wordnet')\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0bb555f",
   "metadata": {},
   "source": [
    "## 1. Data Partitioning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be85ea1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking number of true and false values for each labeled data files from last phase of project.\n",
    "# output folder path\n",
    "# IGNORE THIS STEP IF ERROR PERSIST\n",
    "os.chdir(\"../A_2_output\")\n",
    "fl = os.listdir()\n",
    "df_list = []\n",
    "for i in fl:\n",
    "    print(i)\n",
    "    df = pd.read_csv(i)\n",
    "    df_list.append(df)\n",
    "    #print(df.describe())\n",
    "    a = list(df.label)\n",
    "    print(\"True's: {0} False's: {1}\".format(\n",
    "        a.count(True), a.count(False)),\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "44846dad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of the prim data:  (1195, 2)\n",
      "                                                text  label\n",
      "0  Putin After Announcing #CovidVaccine #Russian ...      1\n",
      "1  Courtesy: WA! #WhatsApp #COVID #CovidVaccine h...      1\n",
      "2  4 of the vaccines Jared bought are expected to...      1\n",
      "3  One day you will realize CDC Guidelines magica...      0\n",
      "4  Im far from lying.  Current CDC guidelines is ...      1 \n",
      "\n",
      "\n",
      "Shape of the sec data:  (1500, 2)\n",
      "                                                text  label\n",
      "0         Language Education in the Time of COVID-19      0\n",
      "1                                 COVID-19 Test Kits      0\n",
      "2                                 COVID 19 IN PRISON      0\n",
      "3                                     Get Waled Home      0\n",
      "4  Make pass/fail available for Mississippi State...      0\n"
     ]
    }
   ],
   "source": [
    "# we choose vaccination as we have majority of T's\n",
    "\n",
    "# using twitter data as my primary dataset(assigned primary topic)\n",
    "df = pd.read_csv(\"../A_2_output/twitter_topic_vaccination.csv\")\n",
    "# using change org data as my secondary dataset\n",
    "sec_df = pd.read_csv(\"../A_2_output/change.org_topic_vaccination.csv\")\n",
    "\n",
    "print('Shape of the prim data: ', df.shape)\n",
    "df[\"label\"] = df[\"label\"].astype(int)\n",
    "print(df.head(),\"\\n\\n\")\n",
    "\n",
    "print('Shape of the sec data: ', sec_df.shape)\n",
    "sec_df[\"label\"] = sec_df[\"label\"].astype(int)\n",
    "print(sec_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a7ce5f38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(800,)\n",
      "(395,)\n",
      "(800,)\n",
      "(395,)\n"
     ]
    }
   ],
   "source": [
    "# split train and test data \n",
    "# [train - 70%, test - 30%]\n",
    "text_train, text_test, y_train, y_test = train_test_split(df.text,df.label,test_size = 0.33)\n",
    "\n",
    "print(text_train.shape)\n",
    "print(text_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3b828cc",
   "metadata": {},
   "source": [
    "## 2. Baseline model training\n",
    "Here we are using below models:\n",
    "1. Logistic regression with no penality\n",
    "2. Logistic regression with l2 penality\n",
    "3. RandomForest Classificatin "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e1f231a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalizing data(pre-process) and tranforming data to matrix\n",
    "vectorizer = TfidfVectorizer(min_df=3, stop_words=\"english\").fit(text_train)\n",
    "X_train = vectorizer.transform(text_train)\n",
    "X_test = vectorizer.transform(text_test)\n",
    "X_sec_data = vectorizer.transform(sec_df.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f93c103",
   "metadata": {},
   "source": [
    "### a. Logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f7415176",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logistic regression model with no penality\n",
    "lr_model = LogisticRegression(penalty=\"none\", \n",
    "                              multi_class=\"multinomial\",\n",
    "                              solver=\"lbfgs\").fit(X_train, y_train)\n",
    "y_pred_lr_test = lr_model.predict(X_test)\n",
    "y_sec_data_predict = lr_model.predict(X_sec_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccc74a3d",
   "metadata": {},
   "source": [
    "####  Primary test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9d448d73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic regression with no penality - Accuracy:  0.8734177215189873 \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.85      0.86       187\n",
      "           1       0.87      0.89      0.88       208\n",
      "\n",
      "    accuracy                           0.87       395\n",
      "   macro avg       0.87      0.87      0.87       395\n",
      "weighted avg       0.87      0.87      0.87       395\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# primary test data accuracy with logistic regression(no penality)\n",
    "print(\"Logistic regression with no penality - Accuracy: \", accuracy_score(y_test, y_pred_lr_test),\"\\n\")\n",
    "print(classification_report(y_test, y_pred_lr_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5a60594",
   "metadata": {},
   "source": [
    "####  Secondary dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f73dee1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic regression with no penality - Accuracy[SECONDARY DATA]:  0.5373333333333333 \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.53      0.69      1474\n",
      "           1       0.03      0.77      0.05        26\n",
      "\n",
      "    accuracy                           0.54      1500\n",
      "   macro avg       0.51      0.65      0.37      1500\n",
      "weighted avg       0.98      0.54      0.68      1500\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# secondary test data accuracy with logistic regression(no penality)\n",
    "print(\"Logistic regression with no penality - Accuracy[SECONDARY DATA]: \",\n",
    "      accuracy_score(sec_df.label, y_sec_data_predict),\"\\n\")\n",
    "print(classification_report(sec_df.label, y_sec_data_predict))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1903607d",
   "metadata": {},
   "source": [
    "### b. Logistic regression with l2 penality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "371d9353",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logistic regression model with penality\n",
    "lr2_model_w_penality = LogisticRegression(penalty=\"l2\", \n",
    "                               solver=\"lbfgs\",\n",
    "                               multi_class=\"multinomial\",\n",
    "                               max_iter=1001,\n",
    "                               C=9).fit(X_train, y_train)\n",
    "y_pred_lr_penality_test = lr2_model_w_penality.predict(X_test)\n",
    "y_sec_data_predict_w_pen = lr2_model_w_penality.predict(X_sec_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cba8cdb",
   "metadata": {},
   "source": [
    "####  Primary test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1aeb5eca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic regression with l2 penality - Accuracy:  0.8835443037974684 \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.84      0.87       187\n",
      "           1       0.87      0.92      0.89       208\n",
      "\n",
      "    accuracy                           0.88       395\n",
      "   macro avg       0.89      0.88      0.88       395\n",
      "weighted avg       0.88      0.88      0.88       395\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# primary test data accuracy using logistic regression(no penality)\n",
    "print(\"Logistic regression with l2 penality - Accuracy: \",accuracy_score(y_test, y_pred_lr_penality_test),\"\\n\")\n",
    "print(classification_report(y_test, y_pred_lr_penality_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a871657",
   "metadata": {},
   "source": [
    "#### Secondary dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c80e11a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic regression with no penality - Accuracy[SECONDARY DATA]:  0.5753333333333334 \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.57      0.73      1474\n",
      "           1       0.03      0.73      0.06        26\n",
      "\n",
      "    accuracy                           0.58      1500\n",
      "   macro avg       0.51      0.65      0.39      1500\n",
      "weighted avg       0.98      0.58      0.71      1500\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# secondary test data accuracy using logistic regression(l2 penality)\n",
    "print(\"Logistic regression with no penality - Accuracy[SECONDARY DATA]: \",\n",
    "      accuracy_score(sec_df.label, y_sec_data_predict_w_pen),\"\\n\")\n",
    "print(classification_report(sec_df.label, y_sec_data_predict_w_pen))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "839752c2",
   "metadata": {},
   "source": [
    "### c. Random Forest Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "bb08c042",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classification model with RandomForestClassifier\n",
    "clf = RandomForestClassifier()\n",
    "clf.fit(X_train, y_train)\n",
    "rf_pred = clf.predict(X_test)\n",
    "rf_sec_pred = clf.predict(X_sec_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "225852f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestClassifier - primary test data - Accuracy:  0.9012658227848102 \n",
      "\n",
      "RandomForestClassifier - secondary test data - Accuracy:  0.6453333333333333 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# primary and secondary test data accuracy using Random Forest\n",
    "print(\"RandomForestClassifier - primary test data - Accuracy: \", accuracy_score(y_test, rf_pred),\"\\n\")\n",
    "print(\"RandomForestClassifier - secondary test data - Accuracy: \", accuracy_score(sec_df.label, rf_sec_pred),\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bae48fb",
   "metadata": {},
   "source": [
    "## 3. Model evaluation-1\n",
    "Below is the tabular form of above evaluated data with all models accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f53ef6d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model                                                       accuracy\n",
      "--------------------------------------------------------  ----------\n",
      "Logistic Regression with no penality - Primary test data    0.873418\n",
      "Logistic Regression with no penality - Secondary data       0.537333\n",
      "Logistic Regression with l2 penality - Primary test data    0.883544\n",
      "Logistic Regression with l2 penality - Secondary data       0.575333\n",
      "Random Forest Classifier - Primary test data                0.901266\n",
      "Random Forest Classifier - Secondary data                   0.645333\n"
     ]
    }
   ],
   "source": [
    "table = [[\"Logistic Regression with no penality - Primary test data\", accuracy_score(y_test, y_pred_lr_test)], \n",
    "                                              ['Logistic Regression with no penality - Secondary data', accuracy_score(sec_df.label, y_sec_data_predict)],\n",
    "                                              ['Logistic Regression with l2 penality - Primary test data', accuracy_score(y_test, y_pred_lr_penality_test)],\n",
    "                                              ['Logistic Regression with l2 penality - Secondary data', accuracy_score(sec_df.label, y_sec_data_predict_w_pen)],\n",
    "                                              ['Random Forest Classifier - Primary test data', accuracy_score(y_test, rf_pred)],\n",
    "                                              ['Random Forest Classifier - Secondary data', accuracy_score(sec_df.label, rf_sec_pred)],\n",
    "                                             ]\n",
    "print(tabulate(table, headers=['Model', 'accuracy']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1311c3b",
   "metadata": {},
   "source": [
    "## 4. Feature engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62568533",
   "metadata": {},
   "source": [
    "### a. Pre-processing\n",
    "1. Removing all non alphabetic using regular expression([^A-Za-z#]).\n",
    "2. Converting text to lower case\n",
    "3. Converting each words to there stems(using stremmer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "43880874",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pre processing data(stem, applying regex to remove links, etc..) \n",
    "\n",
    "def lemmatize_stemming(text):\n",
    "    return stemmer.stem(WordNetLemmatizer().lemmatize(text, pos='v'))\n",
    "\n",
    "#extract hash tags list(map(lambda x, y: x - y, [2, 4, 6], [1, 3, 5]))\n",
    "def extract_hash_tags(s):\n",
    "    return set(part[1:] for part in s.split() if part.startswith('#'))\n",
    "\n",
    "# Tokenize and lemmatize\n",
    "def preprocess(text):\n",
    "    text = (re.sub('[^#A-Za-z]', ' ', re.sub(r'http\\S+', '', text))).lower()\n",
    "    result=[]\n",
    "    for token in gensim.utils.simple_preprocess(text) :\n",
    "        if token not in gensim.parsing.preprocessing.STOPWORDS and len(token) > 3:\n",
    "            result.append(lemmatize_stemming(token))\n",
    "    result.extend(list(map(lambda x:\"#\"+x,extract_hash_tags(text))))       \n",
    "    return \" \".join(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "055ff141",
   "metadata": {},
   "outputs": [],
   "source": [
    "post_df_text = []\n",
    "post_sec_df_text = []\n",
    "\n",
    "for doc in df.text:\n",
    "    post_df_text.append(preprocess(doc))\n",
    "for doc in sec_df.text:\n",
    "    post_sec_df_text.append(preprocess(doc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5a688cde",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1195\n",
      "1500\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['putin announc covidvaccin russian #covidvaccine #russian',\n",
       " 'courtesi whatsapp covid covidvaccin #covidvaccine #covid #whatsapp',\n",
       " 'vaccin jar buy expect fail trump refus join global']"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(post_df_text))\n",
    "print(len(post_sec_df_text))\n",
    "post_df_text[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "79feed98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating the feature matrix \n",
    "matrix = CountVectorizer(max_features=1500)\n",
    "X = matrix.fit_transform(post_df_text).toarray()\n",
    "y = df.label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "7dcb7a62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(800, 1500)\n",
      "(800,)\n",
      "(395, 1500)\n",
      "(395,)\n",
      "(1500, 1500)\n",
      "(1500,)\n"
     ]
    }
   ],
   "source": [
    "# splitting data to train and test\n",
    "X_train_new, X_test_new, y_train_new, y_test_new, df_train, df_test = train_test_split(X, y, post_df_text, test_size = 0.33)\n",
    "\n",
    "X_sec_test_new = matrix.fit_transform(post_sec_df_text).toarray()\n",
    "y_sec_test_new = sec_df.label\n",
    "\n",
    "print(X_train_new.shape)\n",
    "print(y_train_new.shape)\n",
    "print(X_test_new.shape)\n",
    "print(y_test_new.shape)\n",
    "print(X_sec_test_new.shape)\n",
    "print(y_sec_test_new.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "0264ec74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform matrix to tf*idf vector\n",
    "tf_transformer = TfidfTransformer(use_idf=False).fit(X)\n",
    "X_train_tf = tf_transformer.transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09aacc26",
   "metadata": {},
   "source": [
    "### b. Calculating accuracy before adding features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "1d2865c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9164556962025316\n"
     ]
    }
   ],
   "source": [
    "# Train a text categorization model before feature addition through vector\n",
    "\n",
    "# Logistic regression model with l2 penality after feature addition\n",
    "lr2_model = LogisticRegression(penalty=\"l2\", \n",
    "                               solver=\"lbfgs\",\n",
    "                               multi_class=\"multinomial\",\n",
    "                               max_iter=1001,\n",
    "                               C=10).fit(X_train_new, y_train_new)\n",
    "y_lr2_test_w_pre = lr2_model.predict(X_test_new)\n",
    "\n",
    "print(accuracy_score(y_test_new, y_lr2_test_w_pre))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b83ab3f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Primary test data:  0.9417721518987342\n"
     ]
    }
   ],
   "source": [
    "clf = RandomForestClassifier()\n",
    "clf.fit(np.array(X_train_new), y_train_new)\n",
    "pred = clf.predict(X_test_new)\n",
    "before_pre_accu = accuracy_score(y_test_new,pred)\n",
    "print(\"Primary test data: \",before_pre_accu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "69024558",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_gram_range = (1, 1)\n",
    "stop_words = \"english\"\n",
    "\n",
    "# here newdf is the text with vaccinations as true\n",
    "newdf = df.query('label == 1')\n",
    "newdf = pd.DataFrame(newdf[\"text\"])\n",
    "# Extract all words/phrases\n",
    "count = CountVectorizer(ngram_range=n_gram_range, stop_words=stop_words).fit(newdf.text)\n",
    "all_words = count.get_feature_names_out()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "7bdc843b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(687, 1)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "newdf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "ac2e4390",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SentenceTransformer('distilbert-base-nli-mean-tokens')\n",
    "doc_embedding = model.encode(df.text)\n",
    "word_embeddings = model.encode(all_words)\n",
    "top = 5\n",
    "distances = cosine_similarity(doc_embedding, word_embeddings)\n",
    "keywords = [all_words[index] for index in distances.argsort()[0][-top:]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "8da5635a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'038',\n",
       " '4ginkashmir',\n",
       " 'ABNTelugu',\n",
       " 'Aadhar',\n",
       " 'AatmaNirbharBharat',\n",
       " 'America',\n",
       " 'AstraZeneca',\n",
       " 'Australia',\n",
       " 'BREAKING',\n",
       " 'BharatBiotech',\n",
       " 'BigPharma',\n",
       " 'BiharElections',\n",
       " 'BiharElections2020',\n",
       " 'Biharis',\n",
       " 'BillGates',\n",
       " 'BillGatesBioTerrorist',\n",
       " 'Bitcoin',\n",
       " 'Brahmans',\n",
       " 'Brazil',\n",
       " 'Breaking',\n",
       " 'BurnolForAirasia',\n",
       " 'CCP',\n",
       " 'CDC',\n",
       " 'CDCGuidelines',\n",
       " 'COVAXIN',\n",
       " 'COVID',\n",
       " 'COVID19',\n",
       " 'COVID1984',\n",
       " 'COVID19Aus',\n",
       " 'COVID19India',\n",
       " 'COVID19pt',\n",
       " 'COVID19vaccine',\n",
       " 'COVID2019',\n",
       " 'COVIDIOTS',\n",
       " 'COVIDLongHaulers',\n",
       " 'COVIDVACCINE',\n",
       " 'COVIDVIC19',\n",
       " 'COVIDVaccine',\n",
       " 'COVID_19',\n",
       " 'COVID__19',\n",
       " 'COVIDvaccine',\n",
       " 'COVIDー19',\n",
       " 'COVISHIELD',\n",
       " 'Cargo',\n",
       " 'ChildAbuse',\n",
       " 'China',\n",
       " 'Chinese',\n",
       " 'Corona',\n",
       " 'CoronaUpdatesInIndia',\n",
       " 'CoronaVaccine',\n",
       " 'CoronaVirus',\n",
       " 'CoronaVirusUpdates',\n",
       " 'Coronavirus',\n",
       " 'CoronavirusOutbreak',\n",
       " 'CoronavirusPandemic',\n",
       " 'CoronavirusVaccine',\n",
       " 'Covaxin',\n",
       " 'Covid',\n",
       " 'Covid19',\n",
       " 'Covid19Millionaires',\n",
       " 'Covid19UK',\n",
       " 'CovidHoax',\n",
       " 'CovidVaccine',\n",
       " 'CovidVaccineRace',\n",
       " 'Covid_19',\n",
       " 'Covidshield',\n",
       " 'Covidvaccine',\n",
       " 'Covishield',\n",
       " 'DCGI',\n",
       " 'DMSB',\n",
       " 'DeltaVariant',\n",
       " 'Democrats',\n",
       " 'DivaLasVegas2021',\n",
       " 'DrHarshvardhan',\n",
       " 'EU',\n",
       " 'EconomicBoycott',\n",
       " 'Education',\n",
       " 'Egypt',\n",
       " 'ElectionCommission',\n",
       " 'ExaAMRY',\n",
       " 'ExaBFF',\n",
       " 'ExaBLINK',\n",
       " 'ExposeBillGatesDay',\n",
       " 'FDA',\n",
       " 'Feluda',\n",
       " 'FluShot',\n",
       " 'FollowTheScience',\n",
       " 'Gates',\n",
       " 'GatesFoundation',\n",
       " 'GetVaxxed',\n",
       " 'GrimReaper',\n",
       " 'Health',\n",
       " 'HealthCare',\n",
       " 'HealthMinister',\n",
       " 'Hyderabad',\n",
       " 'IPL2020',\n",
       " 'IWillNotTakeTheVaccine',\n",
       " 'India',\n",
       " 'Individualism',\n",
       " 'Indore',\n",
       " 'Iran',\n",
       " 'Italian',\n",
       " 'JammuKashmir',\n",
       " 'Johnson',\n",
       " 'Johnsonandjohnson',\n",
       " 'ListenToScientists',\n",
       " 'Lockdown2',\n",
       " 'LongCovid',\n",
       " 'MS',\n",
       " 'Mandatory',\n",
       " 'MardiGras',\n",
       " 'Mask',\n",
       " 'Masks',\n",
       " 'MediaCircus',\n",
       " 'Medicine',\n",
       " 'Moderna',\n",
       " 'Modernavaccine',\n",
       " 'MoscowMitch',\n",
       " 'Mumbai',\n",
       " 'MythAndFact',\n",
       " 'NORTHKOREA',\n",
       " 'NWO',\n",
       " 'NZPolitics',\n",
       " 'Nazi',\n",
       " 'Neurological',\n",
       " 'NirmalaSitharaman',\n",
       " 'NotMyPM',\n",
       " 'Novavax',\n",
       " 'Nurses',\n",
       " 'OctoberSurprise',\n",
       " 'OxfordUniversity',\n",
       " 'PFIZER',\n",
       " 'PandemicIsEnding',\n",
       " 'PaulOffit',\n",
       " 'Pfizer',\n",
       " 'Pharmaceutical',\n",
       " 'Phase3Trials',\n",
       " 'PolioVaccine',\n",
       " 'Pope',\n",
       " 'PopeFrancis',\n",
       " 'Pune',\n",
       " 'PuneHospital',\n",
       " 'Putin',\n",
       " 'PutinsPuppet',\n",
       " 'Russia',\n",
       " 'Russian',\n",
       " 'RussianVaccine',\n",
       " 'RuthBaderGinsburg',\n",
       " 'STOCKS',\n",
       " 'SaveOurChildren',\n",
       " 'SaveTheWorld',\n",
       " 'ScottyFromBunnings',\n",
       " 'ScottyFromMarketing',\n",
       " 'SerumInstIndia',\n",
       " 'Sinopharm',\n",
       " 'Sinovac',\n",
       " 'SomethingSpecial',\n",
       " 'SouthAfrica',\n",
       " 'Sputnik',\n",
       " 'SputnikV',\n",
       " 'TCACC2020',\n",
       " 'TYT',\n",
       " 'Tata',\n",
       " 'TheNewNormal',\n",
       " 'Trump',\n",
       " 'TrumpPutin',\n",
       " 'TrumpRussia',\n",
       " 'TrumpUnfit4POTUS',\n",
       " 'Twitter',\n",
       " 'UAE',\n",
       " 'UNICEF',\n",
       " 'UNMASKOURCHILDREN',\n",
       " 'USA',\n",
       " 'USElections',\n",
       " 'USHealth',\n",
       " 'UnitedStated',\n",
       " 'VAXXED',\n",
       " 'VOTEBLUE22',\n",
       " 'Vaccine',\n",
       " 'VaccineConfidence',\n",
       " 'VaccineSafety',\n",
       " 'VaccineTrial',\n",
       " 'Vaccines',\n",
       " 'VaccinesWork',\n",
       " 'Valneva',\n",
       " 'Vaxnews',\n",
       " 'VladimirPutin',\n",
       " 'Warpspeed',\n",
       " 'WednesdayThoughts',\n",
       " 'WhatsApp',\n",
       " 'auspol',\n",
       " 'billgates',\n",
       " 'booster',\n",
       " 'cardiotwitter',\n",
       " 'carryminati',\n",
       " 'cdnpoli',\n",
       " 'clinicaltrial',\n",
       " 'compromise',\n",
       " 'conspiracytheory',\n",
       " 'coronavaccine',\n",
       " 'coronavirus',\n",
       " 'coronavirusvaccine',\n",
       " 'covid',\n",
       " 'covid19',\n",
       " 'covid19nz',\n",
       " 'covid19vaccine',\n",
       " 'covidVACCINE',\n",
       " 'covid_19',\n",
       " 'covidbriefing',\n",
       " 'covidfreeworld',\n",
       " 'covidvaccine',\n",
       " 'covidvaccinerace',\n",
       " 'covidwarriors',\n",
       " 'covishield',\n",
       " 'delhs',\n",
       " 'delusional',\n",
       " 'doodlerbasically',\n",
       " 'dragracevegas',\n",
       " 'dream',\n",
       " 'dreamed',\n",
       " 'getvaccinated',\n",
       " 'globalhealth',\n",
       " 'googlesearch',\n",
       " 'health',\n",
       " 'healthID',\n",
       " 'holocaust',\n",
       " 'homecareassistance',\n",
       " 'hope',\n",
       " 'inktober2020',\n",
       " 'lilly',\n",
       " 'lockdown',\n",
       " 'logistics',\n",
       " 'mandatoryvaccination',\n",
       " 'mandatoryvaccine',\n",
       " 'mask',\n",
       " 'medtwitter',\n",
       " 'nepalindiaborder',\n",
       " 'nepaloncorona',\n",
       " 'nothanks',\n",
       " 'nzpol',\n",
       " 'ourcallingisyou',\n",
       " 'oxfordvaccine',\n",
       " 'pandemic',\n",
       " 'peaceout',\n",
       " 'pharmaceutical',\n",
       " 'prompt',\n",
       " 'pune',\n",
       " 'radio',\n",
       " 'russia',\n",
       " 'russiavaccine',\n",
       " 'sarscov2',\n",
       " 'scamdemic2020',\n",
       " 'silverbullet',\n",
       " 'sputnik',\n",
       " 'supplychain',\n",
       " 'toi',\n",
       " 'trending',\n",
       " 'trudeauvaccinefailure',\n",
       " 'usa',\n",
       " 'vacation',\n",
       " 'vaccinate',\n",
       " 'vaccinated',\n",
       " 'vaccination',\n",
       " 'vaccinationdream',\n",
       " 'vaccine',\n",
       " 'vaccinedevelopment',\n",
       " 'vaccines',\n",
       " 'vaccinetrials',\n",
       " 'vacine',\n",
       " 'vaxart',\n",
       " 'vaxnews',\n",
       " 'visitingangels',\n",
       " 'webnews21',\n",
       " 'wethePeople',\n",
       " 'whatiwantedtosay',\n",
       " 'wtf'}"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# extracting list of hashtags\n",
    "listofhtags = []\n",
    "for each in newdf.text:\n",
    "    x = re.findall(r\"#(\\w+)\", each)\n",
    "    listofhtags.extend(x)\n",
    "listofhtags = set(listofhtags)\n",
    "listofhtags"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3995a615",
   "metadata": {},
   "source": [
    "### c. Adding Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "1b6b5e67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature engineering functions \n",
    "def check_new_keywords(text):\n",
    "    text = (re.sub('[^#A-Za-z]', ' ', re.sub(r'http\\S+', '', text))).lower()\n",
    "    for each in text.split():\n",
    "        if(each in keywords):\n",
    "            return 1\n",
    "    return 0\n",
    "\n",
    "def check_word_vaccine(text):\n",
    "    return  1 if \"vaccin\" in text else 0\n",
    "\n",
    "def check_word_immune(text):\n",
    "    return  1 if \"immun\" in text else 0\n",
    "\n",
    "def check_htags(text):\n",
    "    x = re.findall(r\"#(\\w+)\", text)\n",
    "    return len(x)>0\n",
    "\n",
    "train_new_feature_array = {\"1\":[],\"2\":[],\"3\":[],\"4\":[]}\n",
    "for doc in df_train:\n",
    "    train_new_feature_array[\"1\"].append(check_new_keywords(doc))\n",
    "    train_new_feature_array[\"2\"].append(check_word_vaccine(doc))\n",
    "    train_new_feature_array[\"3\"].append(check_word_immune(doc))\n",
    "    train_new_feature_array[\"4\"].append(check_htags(doc))\n",
    "    \n",
    "test_new_feature_array = {\"1\":[],\"2\":[],\"3\":[],\"4\":[]}\n",
    "for doc in df_test:\n",
    "    test_new_feature_array[\"1\"].append(check_new_keywords(doc))\n",
    "    test_new_feature_array[\"2\"].append(check_word_vaccine(doc))\n",
    "    test_new_feature_array[\"3\"].append(check_word_immune(doc))\n",
    "    test_new_feature_array[\"4\"].append(check_htags(doc))\n",
    "    \n",
    "sec_test_new_feature_array = {\"1\":[],\"2\":[],\"3\":[],\"4\":[]}\n",
    "for doc in post_sec_df_text:    \n",
    "    sec_test_new_feature_array[\"1\"].append(check_new_keywords(doc))\n",
    "    sec_test_new_feature_array[\"2\"].append(check_word_vaccine(doc))\n",
    "    sec_test_new_feature_array[\"3\"].append(check_word_immune(doc))\n",
    "    sec_test_new_feature_array[\"4\"].append(check_htags(doc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "6519fdc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# shape of datasets after adding new features\n",
      "(800, 1504)\n",
      "(395, 1504)\n",
      "(1500, 1504)\n"
     ]
    }
   ],
   "source": [
    "# adding 4 new features to train,test and secondary data sets\n",
    "X_train_final = np.insert(X_train_new, X_train_new.shape[1], train_new_feature_array[\"1\"], axis=1)\n",
    "X_test_final = np.insert(X_test_new, X_test_new.shape[1], test_new_feature_array[\"1\"], axis=1)\n",
    "X_sec_test_final = np.insert(X_sec_test_new, X_sec_test_new.shape[1], sec_test_new_feature_array[\"1\"], axis=1)\n",
    "\n",
    "remain_feature = [\"2\",\"3\",\"4\"]\n",
    "for i in remain_feature:\n",
    "    X_train_final = np.insert(X_train_final, X_train_final.shape[1], train_new_feature_array[i], axis=1)\n",
    "    X_test_final = np.insert(X_test_final, X_test_final.shape[1], test_new_feature_array[i], axis=1)\n",
    "    X_sec_test_final = np.insert(X_sec_test_final, X_sec_test_final.shape[1], sec_test_new_feature_array[i], axis=1)\n",
    "print(\"# shape of datasets after adding new features\")\n",
    "print(X_train_final.shape)\n",
    "print(X_test_final.shape)\n",
    "print(X_sec_test_final.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac6ed059",
   "metadata": {},
   "source": [
    "### d. Calculating accuracy after adding features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "60efc692",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Primary test data ACCURACY:  0.9063291139240506\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.87      0.89       179\n",
      "           1       0.89      0.94      0.92       216\n",
      "\n",
      "    accuracy                           0.91       395\n",
      "   macro avg       0.91      0.90      0.90       395\n",
      "weighted avg       0.91      0.91      0.91       395\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Logistic regression model with no penality after feature addition\n",
    "lr_model_fea = LogisticRegression(penalty=\"none\", \n",
    "                              multi_class=\"multinomial\",\n",
    "                              solver=\"lbfgs\").fit(X_train_final, y_train_new)\n",
    "y_pred_lr_test_fea = lr_model_fea.predict(X_test_final)\n",
    "y_pred_lr_sec_test_fea = lr_model_fea.predict(X_sec_test_final)\n",
    "print(\"Primary test data ACCURACY: \",accuracy_score(y_test_new, y_pred_lr_test_fea))\n",
    "print(classification_report(y_test_new, y_pred_lr_test_fea))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "65f8385e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Secondary test data ACCURACY:  0.9393333333333334\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.95      0.97      1474\n",
      "           1       0.16      0.62      0.26        26\n",
      "\n",
      "    accuracy                           0.94      1500\n",
      "   macro avg       0.58      0.78      0.61      1500\n",
      "weighted avg       0.98      0.94      0.96      1500\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Secondary test data ACCURACY: \",accuracy_score(y_sec_test_new, y_pred_lr_sec_test_fea))\n",
    "print(classification_report(y_sec_test_new, y_pred_lr_sec_test_fea))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "40220e9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Primary test data ACCURACY:  0.9240506329113924\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.91      0.92       179\n",
      "           1       0.92      0.94      0.93       216\n",
      "\n",
      "    accuracy                           0.92       395\n",
      "   macro avg       0.92      0.92      0.92       395\n",
      "weighted avg       0.92      0.92      0.92       395\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Logistic regression model with l2 penality after feature addition\n",
    "lr2_model_fea = LogisticRegression(penalty=\"l2\", \n",
    "                               solver=\"lbfgs\",\n",
    "                               multi_class=\"multinomial\",\n",
    "                               max_iter=1001,\n",
    "                               C=10).fit(X_train_final, y_train_new)\n",
    "y_lr2_test_fea = lr2_model_fea.predict(X_test_final)\n",
    "y_pred_lr2_sec_test_fea = lr2_model_fea.predict(X_sec_test_final)\n",
    "print(\"Primary test data ACCURACY: \",accuracy_score(y_test_new, y_lr2_test_fea))\n",
    "print(classification_report(y_test_new, y_lr2_test_fea))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "a27635db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Secondary test data ACCURACY:  0.9793333333333333\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99      1474\n",
      "           1       0.43      0.62      0.51        26\n",
      "\n",
      "    accuracy                           0.98      1500\n",
      "   macro avg       0.71      0.80      0.75      1500\n",
      "weighted avg       0.98      0.98      0.98      1500\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Secondary test data ACCURACY: \",accuracy_score(y_sec_test_new, y_pred_lr2_sec_test_fea))\n",
    "print(classification_report(y_sec_test_new, y_pred_lr2_sec_test_fea))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "25ac7bf4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Primary test data ACCURACY:  0.9417721518987342\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.94      0.94       179\n",
      "           1       0.95      0.94      0.95       216\n",
      "\n",
      "    accuracy                           0.94       395\n",
      "   macro avg       0.94      0.94      0.94       395\n",
      "weighted avg       0.94      0.94      0.94       395\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Train a text categorization model after feature addition through vector\n",
    "clf = RandomForestClassifier()\n",
    "clf.fit(np.array(X_train_final), y_train_new)\n",
    "pred = clf.predict(X_test_final)\n",
    "sec_pred = clf.predict(X_sec_test_final)\n",
    "print(\"Primary test data ACCURACY: \",accuracy_score(y_test_new,pred))\n",
    "print(classification_report(y_test_new, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "23a22df4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Secondary test data ACCURACY:  0.9906666666666667\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      1.00      1474\n",
      "           1       0.80      0.62      0.70        26\n",
      "\n",
      "    accuracy                           0.99      1500\n",
      "   macro avg       0.90      0.81      0.85      1500\n",
      "weighted avg       0.99      0.99      0.99      1500\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Secondary test data ACCURACY: \",accuracy_score(y_sec_test_new,sec_pred))\n",
    "print(classification_report(y_sec_test_new, sec_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "44f22a62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model with feature engineering                              accuracy\n",
      "--------------------------------------------------------  ----------\n",
      "Logistic Regression with no penality - Primary test data    0.906329\n",
      "Logistic Regression with no penality - Secondary data       0.939333\n",
      "Logistic Regression with l2 penality - Primary test data    0.924051\n",
      "Logistic Regression with l2 penality - Secondary data       0.979333\n",
      "Random Forest Classifier - Primary test data                0.941772\n",
      "Random Forest Classifier - Secondary data                   0.990667\n"
     ]
    }
   ],
   "source": [
    "table = [[\"Logistic Regression with no penality - Primary test data\", accuracy_score(y_test_new, y_pred_lr_test_fea)], \n",
    "                                              ['Logistic Regression with no penality - Secondary data', accuracy_score(y_sec_test_new, y_pred_lr_sec_test_fea)],\n",
    "                                              ['Logistic Regression with l2 penality - Primary test data', accuracy_score(y_test_new, y_lr2_test_fea)],\n",
    "                                              ['Logistic Regression with l2 penality - Secondary data', accuracy_score(y_sec_test_new, y_pred_lr2_sec_test_fea)],\n",
    "                                              ['Random Forest Classifier - Primary test data', accuracy_score(y_test_new,pred)],\n",
    "                                              ['Random Forest Classifier - Secondary data', accuracy_score(y_sec_test_new,sec_pred)]\n",
    "                                             ]\n",
    "print(tabulate(table, headers=['Model with feature engineering', 'accuracy']))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:root] *",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
